{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions for 20151101_072507.jpg to /mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out/output_20151101_072507.jpg\n",
      "Saved edges data to /mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out_txt/edges_20151101_072507.jpg.txt\n",
      "Predictions shape: (21, 2, 2)\n",
      "Image shape: (480, 640, 3)\n",
      "['20151101_072507.jpg', 'example.jpg', 'istockphoto-1349030917-612x612.jpg']\n",
      "Saved predictions for example.jpg to /mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out/output_example.jpg\n",
      "Saved edges data to /mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out_txt/edges_example.jpg.txt\n",
      "Predictions shape: (458, 2, 2)\n",
      "Image shape: (480, 640, 3)\n",
      "['20151101_072507.jpg', 'example.jpg', 'istockphoto-1349030917-612x612.jpg']\n",
      "Saved predictions for istockphoto-1349030917-612x612.jpg to /mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out/output_istockphoto-1349030917-612x612.jpg\n",
      "Saved edges data to /mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out_txt/edges_istockphoto-1349030917-612x612.jpg.txt\n",
      "Predictions shape: (347, 2, 2)\n",
      "Image shape: (408, 612, 3)\n",
      "['20151101_072507.jpg', 'example.jpg', 'istockphoto-1349030917-612x612.jpg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap as lsc\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "from deeplsd.utils.tensor import batch_to_device\n",
    "from deeplsd.models.deeplsd_inference import DeepLSD\n",
    "from deeplsd.geometry.viz_2d import plot_images, plot_lines\n",
    "\n",
    "# Model config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "conf = {\n",
    "    'detect_lines': True,  # Whether to detect lines or only DF/AF\n",
    "    'line_detection_params': {\n",
    "        'merge': True,  # Whether to merge close-by lines\n",
    "        'filtering': False,  # Whether to filter out lines based on the DF/AF. Use 'strict' to get an even stricter filtering\n",
    "        'grad_thresh': 3,\n",
    "        'grad_nfa': True,  # If True, use the image gradient and the NFA score of LSD to further threshold lines. We recommand using it for easy images, but to turn it off for challenging images (e.g. night, foggy, blurry images)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "ckpt = 'deeplsd_wireframe.tar'\n",
    "ckpt = torch.load(str(ckpt), map_location='cpu')\n",
    "net = DeepLSD(conf)\n",
    "net.load_state_dict(ckpt['model'])\n",
    "net = net.to(device).eval()\n",
    "\n",
    "\n",
    "image_dir = '/mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images'\n",
    "output_dir = '/mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out'  \n",
    "edges_dir = '/mnt/c/Users/USER/Desktop/DeepLSD/DeepLSD/notebooks/images_out_txt' \n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(edges_dir, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Load an image\n",
    "    img = cv2.imread(os.path.join(image_dir, image_file))[:, :, ::-1]\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Detect (and optionally refine) the lines\n",
    "    inputs = {'image': torch.tensor(gray_img, dtype=torch.float, device=device)[None, None] / 255.}\n",
    "    with torch.no_grad():\n",
    "        out = net(inputs)\n",
    "        pred_lines = out['lines'][0]\n",
    "\n",
    "    # Plot the predictions\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plot_images([img], ['DeepLSD lines'], cmaps='gray')\n",
    "    plot_lines([pred_lines], indices=range(1))\n",
    "    plt.title(image_file)\n",
    "\n",
    "    # Save the output image\n",
    "    output_file_path = os.path.join(output_dir, f'output_{image_file}')\n",
    "    plt.savefig(output_file_path, bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to free memory\n",
    "\n",
    "    # Save edges data to a text file\n",
    "    edges_file_path = os.path.join(edges_dir, f'edges_{image_file}.txt')\n",
    "    with open(edges_file_path, 'w') as f:\n",
    "        for line in pred_lines:\n",
    "            f.write(f\"{line.tolist()}\\n\")  # Save each line as a list\n",
    "\n",
    "    print(f\"Saved predictions for {image_file} to {output_file_path}\")\n",
    "    print(f\"Saved edges data to {edges_file_path}\")\n",
    "    print(f\"Predictions shape: {pred_lines.shape}\")\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(image_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
